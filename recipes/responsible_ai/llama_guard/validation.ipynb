{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c29b97c-1f79-4f26-a019-a1f85a85b9c6",
   "metadata": {},
   "source": [
    "# Validating the output of Llama Guard quantized and unquantized\n",
    "\n",
    "This notebook aims to show how to validate Llama Guard performance on a given dataset. The script loads a given dataset and evaluates each prompt individually against Llama Guard. To evaluate performance, we calculate the averate precision of the binary classification for a given prompt. Llama Guard can be run usgin Meta provided weights or directly from Hugging Face. \n",
    "\n",
    "## Dataset format\n",
    "The dataset should be in a `jsonl` file, with an object per line, following this structure:\n",
    "```\n",
    "{\n",
    "    \"prompt\": \"user_input\",\n",
    "    \"generation\": \"model_response\",\n",
    "    \"label\": \"good/bad\", \n",
    "    \"unsafe_content\": [\"O1\"]\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "The `label` has a `good` or `bad` value to define if the content is considered safe or unsafe, respectively.\n",
    "\n",
    "The `unsafe_content` field contains a list of the categories the prompt is violating.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a33bcb2-1c42-4abb-8e4f-fe5df88fca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from enum import Enum\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16d266b2-c232-4c7e-8beb-624a4719d9be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llama-recipes/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from inference import llm_eval, pytorch_llm_eval, AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f361b27c-8601-48e6-b453-14ed051379c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Type(Enum):\n",
    "    HF = \"HF\"\n",
    "    PYTORCH = \"PYTORCH\"\n",
    "\n",
    "def format_prompt(entry, agent_type: AgentType):\n",
    "    prompts = []\n",
    "    if agent_type == AgentType.USER:\n",
    "        prompts = [entry[\"prompt\"]]\n",
    "    else:\n",
    "        prompts = [entry[\"prompt\"], entry[\"generation\"]]\n",
    "\n",
    "    return {\n",
    "        \"prompt\": prompts,\n",
    "        \"agent_type\": agent_type,\n",
    "        \"label\": entry[\"label\"],\n",
    "        \"unsafe_content\": entry[\"unsafe_content\"],\n",
    "        \"idx\": entry[\"idx\"]\n",
    "    }\n",
    "\n",
    "def validate_agent_type(value):\n",
    "    try:\n",
    "        return AgentType(value)\n",
    "    except ValueError:\n",
    "        raise ValueError(f\"Invalid AgentType. Choose from: {[agent_type.value for agent_type in AgentType]}\")\n",
    "\n",
    "def run_validation(jsonl_file_path, agent_type, type: Type, load_in_8bit: bool = True, load_in_4bit: bool = False, ckpt_dir = None):\n",
    "\n",
    "    input_file_path = Path(jsonl_file_path)\n",
    "\n",
    "    agent_type = validate_agent_type(agent_type)\n",
    "    \n",
    "    # Preparing prompts\n",
    "    prompts: List[Tuple[List[str], AgentType, str, str, str]] = []\n",
    "    with open(jsonl_file_path, \"r\") as f:\n",
    "        # i = 0\n",
    "        for i, line in enumerate(f):\n",
    "            entry = json.loads(line)\n",
    "            # if i == 10:\n",
    "            #     break\n",
    "            # i += 1\n",
    "            # Format prompt and add to list\n",
    "            prompt = format_prompt(entry, agent_type)\n",
    "            prompts.append(prompt)\n",
    "\n",
    "    \n",
    "    # Executing evaluation\n",
    "    start = time.time()\n",
    "    if type is Type.HF:\n",
    "        llm_eval(prompts, load_in_8bit=load_in_8bit, load_in_4bit=True, logprobs=True)\n",
    "    else:\n",
    "        pytorch_llm_eval(prompts, ckpt_dir, True)\n",
    "    \n",
    "    end = time.time()\n",
    "    print(f\"evaluation executed in {end - start} seconds\")\n",
    "        \n",
    "    average_precision = parse_logprobs(prompts, type)\n",
    "    print(f\"average precision {average_precision:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9562e5-6580-491c-a418-0d8fe9771cf7",
   "metadata": {},
   "source": [
    "## Average presicion\n",
    "\n",
    "This function calculates the average precision score for a set of prompts based on their log probabilities and labels. \n",
    "\n",
    "The `prompts` contain the logprobs calculated for each result by Llama Guard when evaluating the prompts or prompt and generation. \n",
    "\n",
    "The `type` is used to identify if the logprobs are comming from a Hugging Face model or plain pytorch model.\n",
    "\n",
    "The logprob is converted back into probability by exponentiating it (`np.exp`)\n",
    "\n",
    "The probability for `unsafe` when the result is `safe` is calculated using the heuristic 1 - `safe`. As this is a banary classification problem, it should be close to the real value for `unsafe`.\n",
    "\n",
    "The average presicion is calculated with the binary labels from the expected value for each prompt or prompt/generation pair and the probability of generating the unsafe token for each.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d04d0097-951f-477f-8493-48008cc5c306",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_logprobs(prompts, type: Type):\n",
    "    positive_class_probs = []\n",
    "    for prompt in prompts:\n",
    "        prob = np.exp(prompt[\"logprobs\"][0]) if type is Type.PYTORCH else np.exp(prompt[\"logprobs\"][0][1])\n",
    "        if \"unsafe\" in prompt[\"result\"]:\n",
    "            positive_class_probs.append(prob)\n",
    "        else:\n",
    "            # Using heuristic 1 - `safe` probability to calculate the probability of a non selected token in a binary classification\n",
    "            positive_class_probs.append(1 - prob)\n",
    "        \n",
    "    binary_labels = [1 if prompt[\"label\"] == \"bad\" else 0 for prompt in prompts]\n",
    "\n",
    "    return average_precision_score(binary_labels, positive_class_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57483ddd-f3f0-419f-89e5-53fe6d584c8a",
   "metadata": {},
   "source": [
    "**Note:** If you get a `Address already in use` error when running with a local llama guard model, change the port by setting the environment variable to a new one. e.g.: `os.environ[\"MASTER_PORT\"] = \"29501\"` For more details, check `Inference.ipynb`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b660e42c-ac80-4538-bb55-d0fb097949e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts_file = \"valid_prompts_6cat_1122.jsonl\"\n",
    "# prompts_file = \"prompt_train_set_with_label.jsonl\"\n",
    "\n",
    "# When the type is pytorch, there is no quantization options\n",
    "# run_validation(prompts_file, AgentType.USER, Type.PYTORCH, ckpt_dir = \"/home/ubuntu/projects/llama/models/llama_guard-v2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e31c6df-d0c2-417f-be48-a5532c79b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up the cache from running the previous validation\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41c1c1f-ca75-4353-8292-852acc73153e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login to HF to access the model, if necessary\n",
    "# from huggingface_hub import login\n",
    "# login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef07df70-f6bc-459a-9b3d-4cb3bf698757",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/envs/llama-recipes/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/conda/envs/llama-recipes/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.00562596321105957,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 18,
       "postfix": null,
       "prefix": "Loading checkpoint shards",
       "rate": null,
       "total": 4,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd60e997f64c449bacc0481df48613f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Prompts: 100%|\u001b[34m███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████\u001b[0m| 10/10 [00:04<00:00,  2.40it/s]\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "evaluation executed in 11.596012115478516 seconds\n",
      "average precision 98.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# By default, load_in_8bit is true. To run unquantized or with 4bit quantization, set load_in_8bit to False and load_in_4bit to true\n",
    "run_validation(prompts_file, AgentType.USER, Type.HF, load_in_8bit = False, load_in_4bit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cd40ec-57dc-4ac8-aa38-3d274c4e0b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb3dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
